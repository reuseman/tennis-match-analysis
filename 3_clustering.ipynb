{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-5f0e6fa2-db99-483b-a8ff-8e6632c68a1f",
    "deepnote_cell_type": "text-cell-h1",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-691a0c7a-b34b-4aeb-8263-fc8778ceaeee",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5595,
    "execution_start": 1636963344403,
    "source_hash": "7b6b40d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# KMEANS\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster.elbow import KElbowVisualizer \n",
    "from yellowbrick.cluster import silhouette_visualizer \n",
    "\n",
    "# DBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# HIERARCHICAL\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# EMA - XMEANS - FCM\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.cluster.ema import ema, ema_initializer, ema_init_type\n",
    "from pyclustering.cluster.xmeans import xmeans\n",
    "from pyclustering.cluster.fcm import fcm\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "pio.templates.default = \"seaborn\"\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliy functions\n",
    "interesting_features = ['mean_rank_points', 'lrpOnAvgrp', 'age', 'total_matches_played']\n",
    "\n",
    "def show_pca_visualization(cluster_type: str):\n",
    "  df = df_players[df_players.select_dtypes(include = np.number).columns.tolist()].drop(columns = ['ht', 'mean_minutes', 'max_minutes', 'rel_ace', 'rel_df', 'rel_1stIn', 'rel_1stWon', 'rel_2ndWon', '1WonOn1In', '1WonOnTotWon', 'rel_ptsWon', 'rel_bpFaced', 'rel_bpSaved', 'rel_gmsWon'])\n",
    "  df = pd.DataFrame(MinMaxScaler().fit_transform(df), columns=df.columns)\n",
    "  components_df = pd.DataFrame(PCA(n_components=2).fit_transform(df))\n",
    "  px.scatter(x=components_df[0], y=components_df[1], color=df_players[cluster_type]).show()\n",
    "\n",
    "def show_interpretation_table(cluster_type: str):\n",
    "  return df_players.groupby(cluster_type).agg({cluster_type:\"count\", \"mean_rank_points\": \"mean\", \"lrpOnAvgrp\": \"mean\", \"age\": \"mean\", \"matches_won_ratio\": \"mean\", \"total_matches_played\": \"mean\"}).sort_values(by=\"mean_rank_points\", ascending=False).round(2).rename(columns={cluster_type: \"cluster size\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-3f3c4caf-ceb2-4d53-86ae-4b954c542539",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19,
    "execution_start": 1636963350007,
    "source_hash": "7018f5ed",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_players = pd.read_csv(\"./datasets/players.csv\", index_col=0)\n",
    "feautures = ['max_tourney_revenue', 'mean_rank_points', 'lrpOnMxrp', 'matches_won_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feautures:\n",
    "    df_players[feature].hist().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_players[feautures].reset_index(drop=True)\n",
    "df_data = df_data.round(3)\n",
    "\n",
    "# Transformations\n",
    "#df_data['mean_rank_points'] = np.log(df_data['mean_rank_points'])\n",
    "\n",
    "# Plot\n",
    "df_data['mean_rank_points'].hist().show()\n",
    "df_data = pd.DataFrame(MinMaxScaler().fit_transform(df_data), columns=df_data.columns)\n",
    "df_data.boxplot(column=feautures).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-5fc1c385-044d-4c46-8322-a804af0bb406",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-c8897fd0-1a50-4a31-80ef-6579a49f7345",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Find Optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-15126f8c-7be6-4ffb-8f0c-c59694b53b25",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5283,
    "execution_start": 1636963355936,
    "source_hash": "16f7d721"
   },
   "outputs": [],
   "source": [
    "model = KMeans(n_init=10, max_iter=100, init=\"k-means++\")\n",
    "sse_visualizer = KElbowVisualizer(model, k=(2,8), timings=False)\n",
    "sse_visualizer.fit(df_data)\n",
    "sse_visualizer.show()\n",
    "\n",
    "sil_visualizer = KElbowVisualizer(model, k=(2,8), timings=False, metric=\"silhouette\")\n",
    "sil_visualizer.fit(df_data)\n",
    "sil_visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking optimal K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal `k` is 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00012-55d6093c-c243-468c-b71c-c240372bd197",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 474,
    "execution_start": 1636963361255,
    "source_hash": "c5e20870"
   },
   "outputs": [],
   "source": [
    "optimal_k = sse_visualizer.elbow_value_\n",
    "kmeans = KMeans(n_clusters=optimal_k, n_init=10, max_iter=100, init=\"k-means++\")\n",
    "kmeans.fit(df_data)\n",
    "\n",
    "df_players[\"cluster_kmeans\"] = kmeans.labels_.astype(str)\n",
    "\n",
    "x = silhouette_visualizer(KMeans(optimal_k, random_state=42), df_data)\n",
    "print(\"The silhoutte score is: \" + str(x.silhouette_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-4d1f58bb-d93e-45a5-9e53-252cdfd4a457",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_interpretation_table(\"cluster_kmeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the k-means centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "for i in range(0, len(kmeans.cluster_centers_)):\n",
    "    plt.plot(kmeans.cluster_centers_[i], marker='o', label='Cluster %s' % i)\n",
    "plt.xticks(range(0, len(df_data.columns)), df_data.columns, fontsize=15)\n",
    "plt.legend(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(df_players, y=\"total_matches_played\", color=\"cluster_kmeans\").show()\n",
    "px.box(df_players, y=\"age\", color=\"cluster_kmeans\").show()\n",
    "px.box(df_players, y=\"max_performance_index\", color=\"cluster_kmeans\").show()\n",
    "#px.histogram(df_players, x=\"cluster_kmeans\", y=\"total_matches_played\", color=\"cluster_kmeans\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pca_visualization(cluster_type=\"cluster_kmeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter matrix of selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00017-bda09fb1-ec70-4202-9dc7-fa808172f50c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 229,
    "execution_start": 1636963364807,
    "source_hash": "e64430a2"
   },
   "outputs": [],
   "source": [
    "px.scatter_matrix(df_players,\n",
    "    dimensions=feautures,\n",
    "    color=\"cluster_kmeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter matrix of interesting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_matrix(df_players,\n",
    "    dimensions=interesting_features,\n",
    "    color=\"cluster_kmeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms of interesting features by gender\n",
    "The only important difference between male and female players that can be seen is that female players tend to be more than the counterpart, nevertheless no discrimination is made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00019-e4b524d9-94de-4d2e-b698-fb1d25b8c99f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9357,
    "execution_start": 1636963365059,
    "source_hash": "1a87d7d5"
   },
   "outputs": [],
   "source": [
    "# to plot the histograms mean reank points is visualize as log(mean_rank_points) to better appreciate the results\n",
    "df_players_to_visualize = df_players\n",
    "interesting_features_to_visualize = ['log_mean_rank_points', 'lrpOnAvgrp', 'age', 'total_matches_played']\n",
    "df_players_to_visualize['log_mean_rank_points'] = np.log(df_players_to_visualize['mean_rank_points'])\n",
    "\n",
    "for feature in interesting_features_to_visualize:\n",
    "  px.histogram(df_players_to_visualize, x=feature, facet_col=\"cluster_kmeans\", color=df_players.gender).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering does not clearly distinguish between classes of players, however it is possible to find fairly defined patterns by observing the following histograms (6, 7, 8, 9) and the plot related to the centroids and the plot regarding the centroids (10).\n",
    "\n",
    "- Cluster 0 represents the young promises: those with low mean rank points, an average low age and on average the ones with the strongest trends of growth (looking at the lrpOnAvgrp).\n",
    "- Cluster 1 represent the strongest players: with experience and a generally higher age. They have high mean rank points and perform the best in term of matches won ratio.\n",
    "- Cluster 2 represent good players with a decreasing trend.\n",
    "- Cluster 3: represents the bad players: with low mean rank points and a decreasing trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practical interpretation\n",
    "\n",
    "Looking at some example we can get a more practical idea of the clusters, in this case distinguishing cluster 1 from 2.\n",
    "\n",
    "Among all the possible examples we show the most famous / strong players so that you can better understand the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players[df_players['cluster_kmeans'] == '1'].sort_values(by='mean_rank_points', ascending=False).loc[:, ['name', 'mean_rank_points', 'age', 'lrpOnAvgrp']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players[df_players['cluster_kmeans'] == '2'].sort_values(by='mean_rank_points', ascending=False).loc[:, ['name', 'mean_rank_points', 'age', 'lrpOnAvgrp']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-796cb1fb-dcc9-404b-a80c-8f08768ec146",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Density-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair-wise distance and then compute distance matrix\n",
    "dist = pdist(X=df_data, metric='euclidean')\n",
    "dist = squareform(dist)\n",
    "\n",
    "\n",
    "kth_distances = {k:[] for k in range(2, 10 +1, 4)}\n",
    "for kth_distance in range(20, 60, 10):\n",
    "    kth_distances[kth_distance] = []\n",
    "\n",
    "for d in dist:\n",
    "    indexes_to_sort_d = np.argsort(d)\n",
    "    for k in kth_distances:\n",
    "        kth_distances[k].append(d[indexes_to_sort_d[k]])\n",
    "\n",
    "fig = go.Figure()\n",
    "for k in kth_distances.keys():\n",
    "    fig.add_trace(go.Scatter(x = np.array(range(0, len(kth_distances[k]))), y = sorted(kth_distances[k]), mode = 'lines' , name = str(k)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(eps, min_samples, dataset, iter_):\n",
    "    # Fit the model\n",
    "    dbscan_model_ = DBSCAN( eps = eps, min_samples = min_samples)\n",
    "    dbscan_model_.fit(dataset)\n",
    "    \n",
    "    # Mean noise point distance metric\n",
    "    noise_indices = dbscan_model_.labels_ == -1\n",
    "    \n",
    "    if True in noise_indices:\n",
    "        neighboors = NearestNeighbors(n_neighbors = 6).fit(dataset)\n",
    "        distances, indices = neighboors.kneighbors(dataset)\n",
    "        noise_distances = distances[noise_indices, 1:]\n",
    "        noise_mean_distance = round(noise_distances.mean(), 3)\n",
    "    else:\n",
    "        noise_mean_distance = None\n",
    "        \n",
    "    # Number of clusters metric\n",
    "    number_of_clusters = len(set(dbscan_model_.labels_[dbscan_model_.labels_ >= 0]))\n",
    "\n",
    "    # Silhouette score\n",
    "    if (number_of_clusters <= 1):\n",
    "        sil = 0\n",
    "    else:\n",
    "        sil = silhouette_score(dataset, dbscan_model_.labels_)\n",
    "\n",
    "    return(noise_mean_distance, number_of_clusters, sil)\n",
    "\n",
    "eps_to_test = [0.01]\n",
    "for eps in np.arange(0.05, 0.30, 0.05):\n",
    "    eps_to_test.append(round(eps,3))\n",
    "\n",
    "min_samples_to_test = [2, 4, 6, 8, 10]\n",
    "for min_samples in range(20, 60, 10):\n",
    "    min_samples_to_test.append(min_samples)\n",
    "\n",
    "# Dataframe per la metrica sulla distanza media dei noise points dai K punti più vicini\n",
    "results_noise = pd.DataFrame( \n",
    "    data = np.zeros((len(eps_to_test),len(min_samples_to_test))), # Empty dataframe\n",
    "    columns = min_samples_to_test, \n",
    "    index = eps_to_test\n",
    ")\n",
    "\n",
    "# Dataframe per la metrica sul numero di cluster\n",
    "results_clusters = pd.DataFrame( \n",
    "    data = np.zeros((len(eps_to_test),len(min_samples_to_test))), # Empty dataframe\n",
    "    columns = min_samples_to_test, \n",
    "    index = eps_to_test\n",
    ")\n",
    "\n",
    "# Dataframe to store the silhouette score for each combo in the grid search\n",
    "results_silhouette = pd.DataFrame(\n",
    "    data = np.zeros((len(eps_to_test), len(min_samples_to_test))),\n",
    "    columns = min_samples_to_test,\n",
    "    index = eps_to_test\n",
    ")\n",
    "\n",
    "iter_ = 0\n",
    "for eps in eps_to_test:\n",
    "    for min_samples in min_samples_to_test:\n",
    "        iter_ += 1\n",
    "        # Calcolo le metriche\n",
    "        noise_metric, cluster_metric, silhouette_metric = get_metrics(eps, min_samples, df_data, iter_)\n",
    "\n",
    "        results_noise.loc[eps, min_samples] = noise_metric\n",
    "        results_clusters.loc[eps, min_samples] = cluster_metric\n",
    "        results_silhouette.loc[eps, min_samples] = silhouette_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm = (results_clusters >= 2) & (results_clusters <= 3)\n",
    "# sm = (results_clusters == 3)\n",
    "sm = (results_clusters >=0 )\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(50,10) )\n",
    "sns.set(font_scale=2.5)\n",
    "sns.heatmap(results_noise[sm], annot = True, ax = ax1, cbar = False, fmt='.2f').set_title(\"METRIC: Mean Noise Points Distance\")\n",
    "sns.heatmap(results_clusters[sm], annot = True, ax = ax2, cbar = False).set_title(\"METRIC: Number of clusters\")\n",
    "sns.heatmap(results_silhouette[sm], annot = True, ax = ax3, cbar = False).set_title(\"METRIC: Silhouette score\")\n",
    "ax1.set_xlabel(\"N\"); ax2.set_xlabel(\"N\") ; ax3.set_xlabel(\"N\")\n",
    "ax1.set_ylabel(\"EPSILON\"); ax2.set_ylabel(\"EPSILON\") ; ax3.set_ylabel(\"EPSILON\")\n",
    "plt.tight_layout(); plt.show()\n",
    "sns.set(font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbscan = DBSCAN(eps=0.9, min_samples=3).fit(df_data)\n",
    "# dbscan = DBSCAN(eps=0.4, min_samples=29).fit(df_data)\n",
    "#dbscan = DBSCAN(eps=0.2, min_samples=5).fit(df_data)\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=6).fit(df_data)\n",
    "\n",
    "results = np.unique(dbscan.labels_, return_counts=True)\n",
    "print(f\"Clusters labels: {results[0]}\\nElements per cluster: {results[1]}\")\n",
    "df_players[\"cluster_dbscan\"] = dbscan.labels_.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_interpretation_table(\"cluster_dbscan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of noise points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players[df_players['cluster_dbscan'] == '-1'][interesting_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pca_visualization(cluster_type=\"cluster_dbscan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter matrix of selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_matrix(df_players,\n",
    "    dimensions=feautures,\n",
    "    color=\"cluster_dbscan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter matrix of interesting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_matrix(df_players,\n",
    "    dimensions=interesting_features,\n",
    "    color=\"cluster_dbscan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following table we can appreciate how DBSCAN discriminated noise points from the the other samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_players, x='mean_rank_points', y='total_matches_played', color = 'cluster_dbscan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "The clusters result fairly balanced in the number of elements and they represented either good or bad players.\n",
    "The noise labelled by DBSCAN was none other than very bad o very good player."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-b12ab06a-5381-496f-88f5-cf08aaef7cbb",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Hierarchical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    # create the counts of samples under each node\n",
    "    \n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some info regarding the clustering and add 'cluster_hierarchical' attribute to dataframe\n",
    "def info(model, df_players, df_data):\n",
    "    results = np.unique(model.labels_, return_counts=True)\n",
    "    print(f\"Clusters labels: {results[0]}\\nElements per cluster: {results[1]}\")\n",
    "\n",
    "    df_players[\"cluster_hierarchical\"] = model.labels_.astype(str)\n",
    "    #df_players = df_players[df_players.select_dtypes(include = np.number).columns.tolist()].drop(columns = ['ht', 'mean_minutes', 'max_minutes', 'rel_ace', 'rel_df', 'rel_1stIn', 'rel_1stWon', 'rel_2ndWon', '1WonOn1In', '1WonOnTotWon', 'rel_ptsWon', 'rel_bpFaced', 'rel_bpSaved', 'rel_gmsWon'])\n",
    "    print(\"Silhouette score: \" + str(silhouette_score(df_data, model.labels_.astype(str))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_value = 25\n",
    "\n",
    "# plot the full dendogram\n",
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None, linkage='ward')\n",
    "model = model.fit(df_data)\n",
    "plot_dendrogram(model, truncate_mode=\"level\", color_threshold=threshold_value, p=4)\n",
    "if threshold_value != None:\n",
    "    plt.axhline(y=threshold_value, color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run again agglomerating up to 2 clusters\n",
    "model = AgglomerativeClustering(n_clusters=2, linkage='ward')\n",
    "model = model.fit(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info(model, df_players, df_data)\n",
    "show_interpretation_table(\"cluster_hierarchical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_matrix(df_players,\n",
    "    dimensions=interesting_features,\n",
    "    color=\"cluster_dbscan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pca_visualization(cluster_type=\"cluster_hierarchical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_value = 1.6\n",
    "\n",
    "# plot the full dendogram\n",
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None, linkage='complete')\n",
    "model = model.fit(df_data)\n",
    "plot_dendrogram(model, truncate_mode=\"level\", color_threshold=threshold_value, p=4)\n",
    "if threshold_value != None:\n",
    "    plt.axhline(y=threshold_value, color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run again agglomerating up to 3 clusters\n",
    "model = AgglomerativeClustering(n_clusters=4, linkage='complete')\n",
    "model = model.fit(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info(model, df_players, df_data)\n",
    "show_interpretation_table(\"cluster_hierarchical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_value = 0.25\n",
    "\n",
    "# plot the full dendogram\n",
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None, linkage='single')\n",
    "model = model.fit(df_data)\n",
    "plot_dendrogram(model, truncate_mode=\"level\", color_threshold=threshold_value, p=4)\n",
    "if threshold_value != None:\n",
    "    plt.axhline(y=threshold_value, color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run again agglomerating up to 4 clusters\n",
    "model = AgglomerativeClustering(n_clusters=4, linkage='ward')\n",
    "model = model.fit(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info(model, df_players, df_data)\n",
    "show_interpretation_table(\"cluster_hierarchical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_value = 0.7\n",
    "\n",
    "# plot the full dendogram\n",
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None, linkage='average')\n",
    "model = model.fit(df_data)\n",
    "plot_dendrogram(model, truncate_mode=\"level\", color_threshold=threshold_value, p=4)\n",
    "if threshold_value != None:\n",
    "    plt.axhline(y=threshold_value, color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run again agglomerating up to 3 clusters\n",
    "model = AgglomerativeClustering(n_clusters=3, linkage='ward')\n",
    "model = model.fit(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info(model, df_players, df_data)\n",
    "show_interpretation_table(\"cluster_hierarchical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_data.values.tolist()\n",
    "amount_clusters=2\n",
    "initial_means, initial_covariance = ema_initializer(df, amount_clusters).initialize(ema_init_type.KMEANS_INITIALIZATION)\n",
    "ema_instance = ema(df, 2, initial_means, initial_covariance, tolerance=100)\n",
    "ema_instance.process()\n",
    "\n",
    "# Get clustering results.\n",
    "clusters = ema_instance.get_clusters()\n",
    "covariances = ema_instance.get_covariances()\n",
    "means = ema_instance.get_centers()\n",
    "\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(f\"Cluster {i}: {len(cluster)}\")\n",
    "\n",
    "for i, cluster in zip(range(len(clusters)), clusters):\n",
    "    df_players.loc[df_players.index[cluster], 'cluster_gm'] = str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pca_visualization(\"cluster_gm\")\n",
    "show_interpretation_table(\"cluster_gm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-b575ff62-84bd-4d6a-b55b-18f871f22505",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## X-MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial centers for xmeans algorithm\n",
    "amount_initial_centers = 2\n",
    "maximum_clusters = 40\n",
    "initial_centers = kmeans_plusplus_initializer(df_data, amount_initial_centers, random_state=42).initialize()\n",
    " \n",
    "# Create instance of X-Means algorithm with Bayesian Information Criterion (BIC) splitting criterion.\n",
    "xmeans_instance = xmeans(df_data, initial_centers, maximum_clusters, tolerance=0.5, random_state=47)\n",
    "xmeans_instance.process()\n",
    " \n",
    "# Extract clustering results: clusters and their centers\n",
    "clusters = xmeans_instance.get_clusters()\n",
    "centers = xmeans_instance.get_centers()\n",
    " \n",
    "# Print total sum of metric errors\n",
    "print(\"Total WCE:\", xmeans_instance.get_total_wce())\n",
    "\n",
    "# Add results to dataset\n",
    "xmeans_clusters = [] \n",
    "for i in range(0, len(clusters)):\n",
    "    for j in clusters[i]:\n",
    "        xmeans_clusters.append((j, i))\n",
    "\n",
    "# sort according to first element of tuple\n",
    "xmeans_clusters.sort(key=lambda tup: tup[0])\n",
    "# keep only second element of tuple\n",
    "xmeans_clusters = np.array([tup[1] for tup in xmeans_clusters])\n",
    "\n",
    "df_players[\"cluster_xmeans\"] = xmeans_clusters.astype(str)\n",
    "print(\"clusters found: \" + str(len(clusters)) + \" on a maximum of \" + str(maximum_clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pca_visualization(\"cluster_xmeans\")\n",
    "show_interpretation_table(\"cluster_xmeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "for i in range(0, len(centers)):\n",
    "    plt.plot(centers[i], marker='o', label='Cluster %s' % i)\n",
    "plt.xticks(range(0, len(df_data.columns)), df_data.columns, fontsize=15)\n",
    "plt.legend(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_matrix(df_players,\n",
    "    dimensions=feautures,\n",
    "    color=\"cluster_kmeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy C-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare initial centers - amount of initial centers defines amount of clusters from which X-Means will\n",
    "# start analysis.\n",
    "amount_initial_centers = 4\n",
    "initial_centers = kmeans_plusplus_initializer(df_data, amount_initial_centers, random_state=42).initialize()\n",
    "\n",
    "# Create instance of Fuzzy C-Means algorithm, run it and get results\n",
    "fcm_instance = fcm(df_data.to_numpy(), initial_centers, m=1.5)\n",
    "fcm_instance.process()\n",
    "clusters = fcm_instance.get_clusters()\n",
    "centers = fcm_instance.get_centers()\n",
    "\n",
    "# Add cluster label to original dataframe\n",
    "fcm_clusters = [] \n",
    "for i in range(0, len(clusters)):\n",
    "    for j in clusters[i]:\n",
    "        fcm_clusters.append((j, i))\n",
    "\n",
    "# sort according to first element of tuple\n",
    "fcm_clusters.sort(key=lambda tup: tup[0])\n",
    "# keep only second element of tuple\n",
    "fcm_clusters = np.array([tup[1] for tup in fcm_clusters])\n",
    "\n",
    "df_players[\"cluster_fcm\"] = fcm_clusters.astype(str)\n",
    "show_interpretation_table(\"cluster_fcm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fuzzy c-means returns the same results from the k-means and that was expeceted given the fact that the real difference is not in the `fcm_instance.get_clusters()` method but in `fcm_instance.get_membership()` that takes in account the fuzzyness"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "86f61efd-3d03-421b-8496-cf838ba66d00",
  "interpreter": {
   "hash": "11bc6520eaf059b9bc04ee98b4f739ace287d2f24aeca2977117dec1068ffc1c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('dm': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
